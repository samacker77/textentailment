{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "hsXlI9_p8CFl",
    "outputId": "279e2aa8-2e7f-4218-a1e5-e6bc5bee99c5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import urllib\n",
    "import sys\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOd1R8xK8EmZ"
   },
   "outputs": [],
   "source": [
    "glove_zip_file = \"glove.6B.zip\"\n",
    "glove_vectors_file = \"glove.6B.50d.txt\"\n",
    "\n",
    "snli_zip_file = \"snli_1.0.zip\"\n",
    "snli_dev_file = \"snli_1.0_dev.txt\"\n",
    "snli_full_dataset_file = \"snli_1.0_train.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QRLXUvPm8QQt"
   },
   "outputs": [],
   "source": [
    "from six.moves.urllib.request import urlretrieve\n",
    "    \n",
    "#large file - 862 MB\n",
    "if (not os.path.isfile(glove_zip_file) and\n",
    "    not os.path.isfile(glove_vectors_file)):\n",
    "    urlretrieve (\"http://nlp.stanford.edu/data/glove.6B.zip\", \n",
    "                 glove_zip_file)\n",
    "\n",
    "#medium-sized file - 94.6 MB\n",
    "if (not os.path.isfile(snli_zip_file) and\n",
    "    not os.path.isfile(snli_dev_file)):\n",
    "    urlretrieve (\"https://nlp.stanford.edu/projects/snli/snli_1.0.zip\", \n",
    "                 snli_zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Av45P4L8ThG"
   },
   "outputs": [],
   "source": [
    "def unzip_single_file(zip_file_name, output_file_name):\n",
    "    \"\"\"\n",
    "        If the outFile is already created, don't recreate\n",
    "        If the outFile does not exist, create it from the zipFile\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(output_file_name):\n",
    "        with open(output_file_name, 'wb') as out_file:\n",
    "            with zipfile.ZipFile(zip_file_name) as zipped:\n",
    "                for info in zipped.infolist():\n",
    "                    if output_file_name in info.filename:\n",
    "                        with zipped.open(info) as requested_file:\n",
    "                            out_file.write(requested_file.read())\n",
    "                            return\n",
    "\n",
    "unzip_single_file(glove_zip_file, glove_vectors_file)\n",
    "unzip_single_file(snli_zip_file, snli_dev_file)\n",
    "# unzip_single_file(snli_zip_file, snli_full_dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2jgE0Pe6-YpQ"
   },
   "outputs": [],
   "source": [
    "glove_wordmap = {}\n",
    "with open(glove_vectors_file, \"r\") as glove:\n",
    "    for line in glove:\n",
    "        name, vector = tuple(line.split(\" \", 1))\n",
    "        glove_wordmap[name] = np.fromstring(vector, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uvUD96RM-b2K"
   },
   "outputs": [],
   "source": [
    "def sentence2sequence(sentence):\n",
    "    \"\"\"\n",
    "     \n",
    "    - Turns an input sentence into an (n,d) matrix, \n",
    "        where n is the number of tokens in the sentence\n",
    "        and d is the number of dimensions each word vector has.\n",
    "    \n",
    "      Tensorflow doesn't need to be used here, as simply\n",
    "      turning the sentence into a sequence based off our \n",
    "      mapping does not need the computational power that\n",
    "      Tensorflow provides. Normal Python suffices for this task.\n",
    "    \"\"\"\n",
    "    tokens = sentence.lower().split(\" \")\n",
    "    rows = []\n",
    "    words = []\n",
    "    #Greedy search for tokens\n",
    "    for token in tokens:\n",
    "        i = len(token)\n",
    "        while len(token) > 0 and i > 0:\n",
    "            word = token[:i]\n",
    "            if word in glove_wordmap:\n",
    "                rows.append(glove_wordmap[word])\n",
    "                words.append(word)\n",
    "                token = token[i:]\n",
    "                i = len(token)\n",
    "            else:\n",
    "                i = i-1\n",
    "    return rows, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "9EhxIKQ9-hPg",
    "outputId": "7d75def1-03a0-4f76-f442-a2d8303700f8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVWUA7yZWUU5wJuZVdT/B9KWvOV4SRN/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize(sentence):\n",
    "    rows, words = sentence2sequence(sentence)\n",
    "    mat = np.vstack(rows)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    shown = ax.matshow(mat, aspect=\"auto\")\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    fig.colorbar(shown)\n",
    "    \n",
    "    ax.set_yticklabels([\"\"]+words)\n",
    "    plt.show()\n",
    "    \n",
    "visualize(\"The quick brown fox jumped over the lazy dog.\")\n",
    "visualize(\"The pretty flowers shone in the sunlight.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "GkD11_TY-mcx",
    "outputId": "ffbae45a-549e-4ad4-833b-478c348ad3ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-8-33127d7a5f16>:2: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "rnn_size = 64\n",
    "rnn = tf.contrib.rnn.BasicRNNCell(rnn_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aMY8dh7z-rVP"
   },
   "outputs": [],
   "source": [
    "#Constants setup\n",
    "max_hypothesis_length, max_evidence_length = 30, 30\n",
    "batch_size, vector_size, hidden_size = 128, 50, 64\n",
    "\n",
    "lstm_size = hidden_size\n",
    "\n",
    "weight_decay = 0.0001\n",
    "\n",
    "learning_rate = 1\n",
    "\n",
    "input_p, output_p = 0.5, 0.5\n",
    "\n",
    "training_iterations_count = 100000\n",
    "\n",
    "display_step = 10\n",
    "\n",
    "def score_setup(row):\n",
    "    convert_dict = {\n",
    "      'entailment': 0,\n",
    "      'neutral': 1,\n",
    "      'contradiction': 2\n",
    "    }\n",
    "    score = np.zeros((3,))\n",
    "    for x in range(1,6):\n",
    "        tag = row[\"label\"+str(x)]\n",
    "        if tag in convert_dict: score[convert_dict[tag]] += 1\n",
    "    return score / (1.0*np.sum(score))\n",
    "\n",
    "def fit_to_size(matrix, shape):\n",
    "    res = np.zeros(shape)\n",
    "    slices = [slice(0,min(dim,shape[e])) for e, dim in enumerate(matrix.shape)]\n",
    "    res[slices] = matrix[slices]\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "1o95Ak5z-tti",
    "outputId": "b0ee8f15-2eb7-4705-ac97-b446a55107d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    }
   ],
   "source": [
    "def split_data_into_scores():\n",
    "    import csv\n",
    "    with open(\"snli_1.0_dev.txt\",\"r\") as data:\n",
    "        train = csv.DictReader(data, delimiter='\\t')\n",
    "        evi_sentences = []\n",
    "        hyp_sentences = []\n",
    "        labels = []\n",
    "        scores = []\n",
    "        for row in train:\n",
    "            hyp_sentences.append(np.vstack(\n",
    "                    sentence2sequence(row[\"sentence1\"].lower())[0]))\n",
    "            evi_sentences.append(np.vstack(\n",
    "                    sentence2sequence(row[\"sentence2\"].lower())[0]))\n",
    "            labels.append(row[\"gold_label\"])\n",
    "            scores.append(score_setup(row))\n",
    "        \n",
    "        hyp_sentences = np.stack([fit_to_size(x, (max_hypothesis_length, vector_size))\n",
    "                          for x in hyp_sentences])\n",
    "        evi_sentences = np.stack([fit_to_size(x, (max_evidence_length, vector_size))\n",
    "                          for x in evi_sentences])\n",
    "                                 \n",
    "        return (hyp_sentences, evi_sentences), labels, np.array(scores)\n",
    "    \n",
    "data_feature_list, correct_values, correct_scores = split_data_into_scores()\n",
    "\n",
    "l_h, l_e = max_hypothesis_length, max_evidence_length\n",
    "N, D, H = batch_size, vector_size, hidden_size\n",
    "l_seq = l_h + l_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y540R1Ly-zha"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "aTTSXZV7-4Go",
    "outputId": "7b4faa5f-3d91-4b85-a8ad-94911f548cef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-9e22ebd21dd7>:1: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eDbkT7VF-6jb"
   },
   "outputs": [],
   "source": [
    "lstm_drop =  tf.contrib.rnn.DropoutWrapper(lstm, input_p, output_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "ERNAsVBk-87w",
    "outputId": "14cb06a5-d05c-4993-eda8-ae53df7145b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-779d23f269cc>:54: static_bidirectional_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:1610: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# N: The number of elements in each of our batches, \n",
    "#   which we use to train subsets of data for efficiency's sake.\n",
    "# l_h: The maximum length of a hypothesis, or the second sentence.  This is\n",
    "#   used because training an RNN is extraordinarily difficult without \n",
    "#   rolling it out to a fixed length.\n",
    "# l_e: The maximum length of evidence, the first sentence.  This is used\n",
    "#   because training an RNN is extraordinarily difficult without \n",
    "#   rolling it out to a fixed length.\n",
    "# D: The size of our used GloVe or other vectors.\n",
    "hyp = tf.placeholder(tf.float32, [N, l_h, D], 'hypothesis')\n",
    "evi = tf.placeholder(tf.float32, [N, l_e, D], 'evidence')\n",
    "y = tf.placeholder(tf.float32, [N, 3], 'label')\n",
    "# hyp: Where the hypotheses will be stored during training.\n",
    "# evi: Where the evidences will be stored during training.\n",
    "# y: Where correct scores will be stored during training.\n",
    "\n",
    "# lstm_size: the size of the gates in the LSTM, \n",
    "#    as in the first LSTM layer's initialization.\n",
    "lstm_back = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "# lstm_back:  The LSTM used for looking backwards \n",
    "#   through the sentences, similar to lstm.\n",
    "\n",
    "# input_p: the probability that inputs to the LSTM will be retained at each\n",
    "#   iteration of dropout.\n",
    "# output_p: the probability that outputs from the LSTM will be retained at \n",
    "#   each iteration of dropout.\n",
    "lstm_drop_back = tf.contrib.rnn.DropoutWrapper(lstm_back, input_p, output_p)\n",
    "# lstm_drop_back:  A dropout wrapper for lstm_back, like lstm_drop.\n",
    "\n",
    "\n",
    "fc_initializer = tf.random_normal_initializer(stddev=0.1) \n",
    "# fc_initializer: initial values for the fully connected layer's weights.\n",
    "# hidden_size: the size of the outputs from each lstm layer.  \n",
    "#   Multiplied by 2 to account for the two LSTMs.\n",
    "fc_weight = tf.get_variable('fc_weight', [2*hidden_size, 3], \n",
    "                            initializer = fc_initializer)\n",
    "# fc_weight: Storage for the fully connected layer's weights.\n",
    "fc_bias = tf.get_variable('bias', [3])\n",
    "# fc_bias: Storage for the fully connected layer's bias.\n",
    "\n",
    "# tf.GraphKeys.REGULARIZATION_LOSSES:  A key to a collection in the graph\n",
    "#   designated for losses due to regularization.\n",
    "#   In this case, this portion of loss is regularization on the weights\n",
    "#   for the fully connected layer.\n",
    "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, \n",
    "                     tf.nn.l2_loss(fc_weight)) \n",
    "\n",
    "x = tf.concat([hyp, evi], 1) # N, (Lh+Le), d\n",
    "# Permuting batch_size and n_steps\n",
    "x = tf.transpose(x, [1, 0, 2]) # (Le+Lh), N, d\n",
    "# Reshaping to (n_steps*batch_size, n_input)\n",
    "x = tf.reshape(x, [-1, vector_size]) # (Le+Lh)*N, d\n",
    "# Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "x = tf.split(x, l_seq,)\n",
    "\n",
    "# x: the inputs to the bidirectional_rnn\n",
    "\n",
    "\n",
    "# tf.contrib.rnn.static_bidirectional_rnn: Runs the input through\n",
    "#   two recurrent networks, one that runs the inputs forward and one\n",
    "#   that runs the inputs in reversed order, combining the outputs.\n",
    "rnn_outputs, _, _ = tf.contrib.rnn.static_bidirectional_rnn(lstm, lstm_back,\n",
    "                                                            x, dtype=tf.float32)\n",
    "# rnn_outputs: the list of LSTM outputs, as a list. \n",
    "#   What we want is the latest output, rnn_outputs[-1]\n",
    "\n",
    "classification_scores = tf.matmul(rnn_outputs[-1], fc_weight) + fc_bias\n",
    "# The scores are relative certainties for how likely the output matches\n",
    "#   a certain entailment: \n",
    "#     0: Positive entailment\n",
    "#     1: Neutral entailment\n",
    "#     2: Negative entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "DCHookog_G2D",
    "outputId": "fa80ddd0-9be3-4d29-b7e5-da42644bf3ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-97a0fabce845>:10: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('Accuracy'):\n",
    "    predicts = tf.cast(tf.argmax(classification_scores, 1), 'int32')\n",
    "    y_label = tf.cast(tf.argmax(y, 1), 'int32')\n",
    "    corrects = tf.equal(predicts, y_label)\n",
    "    num_corrects = tf.reduce_sum(tf.cast(corrects, tf.float32))\n",
    "    accuracy = tf.reduce_mean(tf.cast(corrects, tf.float32))\n",
    "\n",
    "with tf.variable_scope(\"loss\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits = classification_scores, labels = y)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    total_loss = loss + weight_decay * tf.add_n(\n",
    "        tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "opt_op = optimizer.minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yrDewsdl_MFu",
    "outputId": "470e9621-8caf-4809-f1e6-055a501dd97b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/782 [00:02<25:16,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0.0, Minibatch Loss= 1.112793, Training Accuracy= 0.28125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 18/782 [00:03<12:19,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10.0, Minibatch Loss= 1.092364, Training Accuracy= 0.39062\n",
      "Iter 20.0, Minibatch Loss= 1.087251, Training Accuracy= 0.39062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 38/782 [00:03<04:15,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 30.0, Minibatch Loss= 1.091860, Training Accuracy= 0.36719\n",
      "Iter 40.0, Minibatch Loss= 1.089727, Training Accuracy= 0.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 57/782 [00:03<01:34,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 50.0, Minibatch Loss= 1.089526, Training Accuracy= 0.45312\n",
      "Iter 60.0, Minibatch Loss= 1.077253, Training Accuracy= 0.39062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 81/782 [00:04<00:32, 21.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 70.0, Minibatch Loss= 1.085502, Training Accuracy= 0.40625\n",
      "Iter 80.0, Minibatch Loss= 1.065840, Training Accuracy= 0.42188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 101/782 [00:04<00:18, 36.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 90.0, Minibatch Loss= 1.081933, Training Accuracy= 0.43750\n",
      "Iter 100.0, Minibatch Loss= 1.079775, Training Accuracy= 0.42188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 121/782 [00:04<00:13, 49.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 110.0, Minibatch Loss= 1.090609, Training Accuracy= 0.37500\n",
      "Iter 120.0, Minibatch Loss= 1.076373, Training Accuracy= 0.42969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 142/782 [00:05<00:11, 56.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 130.0, Minibatch Loss= 1.074372, Training Accuracy= 0.45312\n",
      "Iter 140.0, Minibatch Loss= 1.090344, Training Accuracy= 0.38281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 162/782 [00:05<00:10, 57.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 150.0, Minibatch Loss= 1.087760, Training Accuracy= 0.44531\n",
      "Iter 160.0, Minibatch Loss= 1.065624, Training Accuracy= 0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 176/782 [00:05<00:10, 60.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 170.0, Minibatch Loss= 1.084098, Training Accuracy= 0.42969\n",
      "Iter 180.0, Minibatch Loss= 1.038939, Training Accuracy= 0.42188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 203/782 [00:06<00:09, 58.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 190.0, Minibatch Loss= 1.102711, Training Accuracy= 0.34375\n",
      "Iter 200.0, Minibatch Loss= 1.032724, Training Accuracy= 0.49219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 223/782 [00:06<00:09, 58.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 210.0, Minibatch Loss= 1.079500, Training Accuracy= 0.45312\n",
      "Iter 220.0, Minibatch Loss= 1.050299, Training Accuracy= 0.53906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 237/782 [00:06<00:09, 59.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 230.0, Minibatch Loss= 1.073444, Training Accuracy= 0.46875\n",
      "Iter 240.0, Minibatch Loss= 1.097890, Training Accuracy= 0.35938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 258/782 [00:07<00:08, 60.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 250.0, Minibatch Loss= 1.067177, Training Accuracy= 0.42969\n",
      "Iter 260.0, Minibatch Loss= 1.085597, Training Accuracy= 0.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 279/782 [00:07<00:08, 60.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 270.0, Minibatch Loss= 1.056641, Training Accuracy= 0.43750\n",
      "Iter 280.0, Minibatch Loss= 1.114130, Training Accuracy= 0.41406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 299/782 [00:07<00:07, 61.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 290.0, Minibatch Loss= 1.092509, Training Accuracy= 0.38281\n",
      "Iter 300.0, Minibatch Loss= 1.023688, Training Accuracy= 0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 320/782 [00:08<00:07, 61.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 310.0, Minibatch Loss= 1.069809, Training Accuracy= 0.39844\n",
      "Iter 320.0, Minibatch Loss= 1.050460, Training Accuracy= 0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 341/782 [00:08<00:07, 58.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 330.0, Minibatch Loss= 1.084667, Training Accuracy= 0.39844\n",
      "Iter 340.0, Minibatch Loss= 1.061602, Training Accuracy= 0.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 362/782 [00:08<00:07, 59.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 350.0, Minibatch Loss= 1.037640, Training Accuracy= 0.44531\n",
      "Iter 360.0, Minibatch Loss= 1.053427, Training Accuracy= 0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 383/782 [00:09<00:06, 59.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 370.0, Minibatch Loss= 1.076025, Training Accuracy= 0.38281\n",
      "Iter 380.0, Minibatch Loss= 1.054759, Training Accuracy= 0.44531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 397/782 [00:09<00:06, 59.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 390.0, Minibatch Loss= 1.061173, Training Accuracy= 0.40625\n",
      "Iter 400.0, Minibatch Loss= 1.066092, Training Accuracy= 0.43750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 422/782 [00:09<00:06, 58.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 410.0, Minibatch Loss= 1.031103, Training Accuracy= 0.53906\n",
      "Iter 420.0, Minibatch Loss= 1.042804, Training Accuracy= 0.50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 442/782 [00:10<00:05, 58.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 430.0, Minibatch Loss= 1.073132, Training Accuracy= 0.42969\n",
      "Iter 440.0, Minibatch Loss= 1.041043, Training Accuracy= 0.43750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 461/782 [00:10<00:05, 58.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 450.0, Minibatch Loss= 1.098371, Training Accuracy= 0.32812\n",
      "Iter 460.0, Minibatch Loss= 1.081946, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 481/782 [00:10<00:05, 56.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 470.0, Minibatch Loss= 1.074165, Training Accuracy= 0.45312\n",
      "Iter 480.0, Minibatch Loss= 1.081513, Training Accuracy= 0.42188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 500/782 [00:11<00:04, 59.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 490.0, Minibatch Loss= 1.044144, Training Accuracy= 0.50781\n",
      "Iter 500.0, Minibatch Loss= 1.069568, Training Accuracy= 0.38281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 519/782 [00:11<00:04, 59.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 510.0, Minibatch Loss= 1.020684, Training Accuracy= 0.53906\n",
      "Iter 520.0, Minibatch Loss= 1.075967, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 539/782 [00:11<00:03, 61.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 530.0, Minibatch Loss= 1.037971, Training Accuracy= 0.53125\n",
      "Iter 540.0, Minibatch Loss= 1.014217, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 560/782 [00:12<00:03, 62.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 550.0, Minibatch Loss= 1.070297, Training Accuracy= 0.43750\n",
      "Iter 560.0, Minibatch Loss= 1.044470, Training Accuracy= 0.43750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 581/782 [00:12<00:03, 58.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 570.0, Minibatch Loss= 1.017610, Training Accuracy= 0.54688\n",
      "Iter 580.0, Minibatch Loss= 1.077074, Training Accuracy= 0.39844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 602/782 [00:12<00:03, 59.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 590.0, Minibatch Loss= 1.018385, Training Accuracy= 0.55469\n",
      "Iter 600.0, Minibatch Loss= 1.033816, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 623/782 [00:13<00:02, 59.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 610.0, Minibatch Loss= 1.026774, Training Accuracy= 0.44531\n",
      "Iter 620.0, Minibatch Loss= 1.008996, Training Accuracy= 0.52344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 637/782 [00:13<00:02, 59.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 630.0, Minibatch Loss= 1.057357, Training Accuracy= 0.49219\n",
      "Iter 640.0, Minibatch Loss= 1.002020, Training Accuracy= 0.49219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 658/782 [00:13<00:02, 60.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 650.0, Minibatch Loss= 1.026549, Training Accuracy= 0.52344\n",
      "Iter 660.0, Minibatch Loss= 0.999318, Training Accuracy= 0.56250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 679/782 [00:14<00:01, 60.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 670.0, Minibatch Loss= 1.046203, Training Accuracy= 0.50000\n",
      "Iter 680.0, Minibatch Loss= 1.036910, Training Accuracy= 0.50781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 699/782 [00:14<00:01, 59.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 690.0, Minibatch Loss= 1.045834, Training Accuracy= 0.46875\n",
      "Iter 700.0, Minibatch Loss= 1.013406, Training Accuracy= 0.51562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 719/782 [00:14<00:01, 61.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 710.0, Minibatch Loss= 0.987604, Training Accuracy= 0.55469\n",
      "Iter 720.0, Minibatch Loss= 0.977185, Training Accuracy= 0.57031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 740/782 [00:15<00:00, 62.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 730.0, Minibatch Loss= 1.068902, Training Accuracy= 0.43750\n",
      "Iter 740.0, Minibatch Loss= 1.037516, Training Accuracy= 0.52344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 761/782 [00:15<00:00, 57.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 750.0, Minibatch Loss= 1.028847, Training Accuracy= 0.55469\n",
      "Iter 760.0, Minibatch Loss= 1.013281, Training Accuracy= 0.56250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:16<00:00, 59.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 770.0, Minibatch Loss= 1.007033, Training Accuracy= 0.53906\n",
      "Iter 780.0, Minibatch Loss= 1.026108, Training Accuracy= 0.47656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Use TQDM if installed\n",
    "tqdm_installed = False\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    tqdm_installed = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Launch the Tensorflow session\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# training_iterations_count: The number of data pieces to train on in total\n",
    "# batch_size: The number of data pieces per batch\n",
    "training_iterations = range(0,training_iterations_count,batch_size)\n",
    "if tqdm_installed:\n",
    "    # Add a progress bar if TQDM is installed\n",
    "    training_iterations = tqdm(training_iterations)\n",
    "\n",
    "for i in training_iterations:\n",
    "\n",
    "    # Select indices for a random data subset\n",
    "    batch = np.random.randint(data_feature_list[0].shape[0], size=batch_size)\n",
    "    \n",
    "    # Use the selected subset indices to initialize the graph's \n",
    "    #   placeholder values\n",
    "    hyps, evis, ys = (data_feature_list[0][batch,:],\n",
    "                      data_feature_list[1][batch,:],\n",
    "                      correct_scores[batch])\n",
    "    \n",
    "    # Run the optimization with these initialized values\n",
    "    sess.run([opt_op], feed_dict={hyp: hyps, evi: evis, y: ys})\n",
    "    # display_step: how often the accuracy and loss should \n",
    "    #   be tested and displayed.\n",
    "    if (i/batch_size) % display_step == 0:\n",
    "        # Calculate batch accuracy\n",
    "        acc = sess.run(accuracy, feed_dict={hyp: hyps, evi: evis, y: ys})\n",
    "        # Calculate batch loss\n",
    "        tmp_loss = sess.run(loss, feed_dict={hyp: hyps, evi: evis, y: ys})\n",
    "        # Display results\n",
    "        print(\"Iter \" + str(i/batch_size) + \", Minibatch Loss= \" + \\\n",
    "              \"{:.6f}\".format(tmp_loss) + \", Training Accuracy= \" + \\\n",
    "              \"{:.5f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "D8IT0bQt_Rmm",
    "outputId": "0eb8313c-c33d-46b6-d2db-f660564c43db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive entailment\n"
     ]
    }
   ],
   "source": [
    "evidences = [\"Maurita and Jade both were at the scene of the car crash.\"]\n",
    "\n",
    "hypotheses = [\"Multiple people saw the accident.\"]\n",
    "\n",
    "sentence1 = [fit_to_size(np.vstack(sentence2sequence(evidence)[0]),\n",
    "                         (30, 50)) for evidence in evidences]\n",
    "\n",
    "sentence2 = [fit_to_size(np.vstack(sentence2sequence(hypothesis)[0]),\n",
    "                         (30,50)) for hypothesis in hypotheses]\n",
    "\n",
    "prediction = sess.run(classification_scores, feed_dict={hyp: (sentence1 * N),\n",
    "                                                        evi: (sentence2 * N),\n",
    "                                                        y: [[0,0,0]]*N})\n",
    "print([\"Positive\", \"Neutral\", \"Negative\"][np.argmax(prediction[0])]+\n",
    "      \" entailment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obyH3K60_rtf"
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLGsjBr__tYk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "textual_entailment",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
